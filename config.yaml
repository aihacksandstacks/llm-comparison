# LLM Comparison Tool Configuration

# Embedding configuration
embeddings:
  provider: "nomic"  # Options: nomic, openai, local
  model: "nomic-embed-text-v1.5"
  dimension: 768
  batch_size: 32
  cache_enabled: true

# LLM providers configuration
llm_providers:
  # Ollama models configuration
  ollama:
    models:
      - name: "llama3"
        parameters:
          temperature: 0.7
          max_tokens: 512
      - name: "mistral"
        parameters:
          temperature: 0.7
          max_tokens: 512
      - name: "phi3"
        parameters:
          temperature: 0.7
          max_tokens: 512
  
  # OpenAI models configuration
  openai:
    models:
      - name: "gpt-3.5-turbo"
        parameters:
          temperature: 0.7
          max_tokens: 512
      - name: "gpt-4"
        parameters:
          temperature: 0.7
          max_tokens: 512

# RAG configuration
rag:
  chunk_size: 512
  chunk_overlap: 128
  similarity_top_k: 5
  
# Evaluation configuration
evaluation:
  metrics:
    - name: "rouge"
      parameters:
        rouge_types: ["rouge1", "rouge2", "rougeL"]
    - name: "semantic_similarity"
      parameters:
        model: "nomic-embed-text-v1.5"
    - name: "response_time"
    - name: "token_count"

# Web crawling configuration
web_crawling:
  max_depth: 3
  max_pages: 100
  timeout: 30  # seconds
  user_agent: "LLM-Comparison-Tool/0.1.0"
  respect_robots_txt: true

# UI configuration
ui:
  theme: "light"  # Options: light, dark
  default_page: "Home"
  max_display_items: 50
  refresh_interval: 5  # seconds 