# Project Roadmap

## Overview
This roadmap outlines the planned development trajectory for the LLM Comparison Tool, including major milestones, deliverables, and timelines.

## Milestones

### Phase 1: Foundation (Weeks 1-2)
- [ ] Complete project scaffolding
- [ ] Set up development environment with Docker
- [ ] Implement basic llama_index ingestion
- [ ] Create initial unit tests

### Phase 2: Core Functionality (Weeks 3-4)
- [ ] Integrate Nomic Atlas embeddings
- [ ] Set up vector store (PostgreSQL + pgvector)
- [ ] Implement basic embedding swapping mechanism
- [ ] Add data ingestion pipeline for initial data types

### Phase 3: Model Integration (Weeks 5-6)
- [ ] Add Ollama backend for local model serving
- [ ] Implement GPU detection for Ollama
- [ ] Integrate Comet ML Opik for evaluation logging
- [ ] Create standardized prompting framework

### Phase 4: Advanced Features (Weeks 7-8)
- [ ] Implement Crawl4AI integration for web ingestion
- [ ] Build complete RAG query pipeline
- [ ] Add batch processing capabilities
- [ ] Develop evaluation metrics and benchmarking

### Phase 5: User Interface (Weeks 9-10)
- [ ] Build Streamlit UI dashboard
- [ ] Implement model selection interface
- [ ] Add visualization components for metrics
- [ ] Create side-by-side comparison views

### Phase 6: MVP Release (Weeks 11-12)
- [ ] Complete comprehensive testing
- [ ] Finalize documentation
- [ ] Optimize performance
- [ ] Release MVP version

## Future Enhancements (Post-MVP)
- Support for additional LLM backends
- Enhanced evaluation metrics
- Possible cloud-hosted demo environment
- User management and collaboration features

*Last Updated: [Current Date]* 